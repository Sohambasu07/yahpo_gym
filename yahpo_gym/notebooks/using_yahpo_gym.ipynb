{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using YAHPO Gym: A quick introduction\r\n",
    "\r\n",
    "Using YAHPO GYM we can benchmark a new Hyperparameter optimization method on a large amount of problems in a very short time-frame.\r\n",
    "\r\n",
    "This tutorial walks us through the core concepts and functionality of ``yahpo_gym` and showscases a practical example.\r\n",
    "\r\n",
    "YAHPO GYM consists of several `scenarios`, e.g. the collection of all benchmark instances in `lcbench` is a `scenario`.\r\n",
    "An `instance` is the concrete task of optimizing hyperparameters of the neural network on a given dataset from OpenML.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Core functionality: Configuration & BenchmarkSet\r\n",
    "\r\n",
    "We first a have a brief look at at the two core classes we will make use of in `YAHPO GYM`: \r\n",
    "- A `Configuration` contains all relevant infos regarding a specific benchmarking scenario e.g. `lcbench`. We can load configurations with the `cfg(<key>)` shortcut.\r\n",
    "- A `BenchmarkSet` can be instantiated using a Configuration (or it's key) and contains the logic used to evaluate the surrogate model for a given query hyperparameter configuration (or set thereof).b"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "To run a benchmark you need to download the ONNX model (`new_model.onnx`), [ConfigSpace](https://automl.github.io/ConfigSpace/) (`config_space.json`) and some encoding info (`encoding.json`).\r\n",
    "\r\n",
    "You can download these [here](https://syncandshare.lrz.de/getlink/fiCMkzqj1bv1LfCUyvZKmLvd/), but **YAHPO GYM** can also autmatically download this for you.\r\n",
    "\r\n",
    "You should pertain the folder structure as on the hosting site (i.e., create a `\"path-to-data\"` directory, for example named `\"multifidelity_data\"`, containing the individual, e.g., `\"lcench\"`, directories)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Initialize the local config & set path for surrogates and metadata\n",
    "from yahpo_gym import local_config\n",
    "local_config.init_config()\n",
    "local_config.set_data_path(\"~/yahpo_models\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# We first load the dict of configurations and the concrete benchmarks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from yahpo_gym.configuration import cfg\n",
    "import yahpo_gym.benchmarks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Now we can print a list of available configurations:\n",
    "print(cfg())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Key             Instances  Cat. HP    Cont. HP   Targets   \n",
      "lcbench         OpenML_task_id  1          8          6         \n",
      "fcnet           task            4          8          3         \n",
      "nb301           CIFAR10         34         1          2         \n",
      "rbv2_svm        task_id         3          6          6         \n",
      "rbv2_ranger     task_id         4          7          6         \n",
      "rbv2_rpart      task_id         2          6          6         \n",
      "rbv2_glmnet     task_id         2          4          6         \n",
      "rbv2_xgboost    task_id         3          14         6         \n",
      "rbv2_aknn       task_id         3          6          6         \n",
      "rbv2_super      task_id         8          33         6         \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# And instantiate a Configuration using a key.\n",
    "conf_lcb = cfg('lcbench')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# We can download all required files using `download_files`.\n",
    "# Files will be downloaded to the data_path (\"~/yahpo_models\") set above.\n",
    "conf_lcb.download_files()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8192' class='' max='2190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      374.06% [8192/2190 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This allows us to query several important properties of the benchmark problem:\r\n",
    "\r\n",
    "- config_id : The id / key of the configuration\r\n",
    "- y_names  : The names of the target variables included in the surrogate model\r\n",
    "- hp_names: The names of all hyperparameters\r\n",
    "- cat_names : The names of categorical hyperparameters\r\n",
    "- cont_names  :  The names of continuous hyperparameters\r\n",
    "- fidelity_params  : The name of the fidelity parameter(s)\r\n",
    "- instance_names : The column pertaining to the available instances in a dataset\r\n",
    "- runtime_name : The name of parameters remeasuring runtime of  the model. \r\n",
    "- data : A `pandas` `DataFrame` containing the data used to train the surrogates. Only available if the data was downloaded."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# We can for example query the target outputs of our surrogate:\n",
    "conf_lcb.y_names"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['time',\n",
       " 'val_accuracy',\n",
       " 'val_cross_entropy',\n",
       " 'val_balanced_accuracy',\n",
       " 'test_cross_entropy',\n",
       " 'test_balanced_accuracy']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BemchmarkSet\r\n",
    "\r\n",
    "A benchmark set allows us to evaluate the surrogate models for a given configuration.\r\n",
    "We can instantiate them similarly to a `Configuration` using the **key**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from yahpo_gym import benchmark_set\n",
    "# Select a Benchmark\n",
    "bench = benchmark_set.BenchmarkSet(\"lcbench\")\n",
    "bench"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BenchmarkInstance (lcbench)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This can again be used to query relevant meta-information:\r\n",
    "- instances: The available instances (in this case OpenML Task Id's)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "cfg(\"lcbench\").config"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'basedir': Path('/home/flo/yahpo_models'),\n",
       " 'download_url': 'https://syncandshare.lrz.de/dl/fiCMkzqj1bv1LfCUyvZKmLvd',\n",
       " 'config_id': 'lcbench',\n",
       " 'model': 'new_model.onnx',\n",
       " 'dataset': 'data.csv',\n",
       " 'config_space': 'config_space.json',\n",
       " 'encoding': 'encoding.json',\n",
       " 'y_names': ['time',\n",
       "  'val_accuracy',\n",
       "  'val_cross_entropy',\n",
       "  'val_balanced_accuracy',\n",
       "  'test_cross_entropy',\n",
       "  'test_balanced_accuracy'],\n",
       " 'cont_names': ['epoch',\n",
       "  'batch_size',\n",
       "  'learning_rate',\n",
       "  'momentum',\n",
       "  'weight_decay',\n",
       "  'num_layers',\n",
       "  'max_units',\n",
       "  'max_dropout'],\n",
       " 'cat_names': ['OpenML_task_id'],\n",
       " 'fidelity_params': ['epoch'],\n",
       " 'runtime_name': 'time',\n",
       " 'model_old': 'model.onnx',\n",
       " 'y_minimize': [True, False, True, False, True, False],\n",
       " 'instance_names': 'OpenML_task_id'}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# List available instances\n",
    "bench.instances[0:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['3945', '7593', '34539', '126025', '126026']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now set an instance, this defines the instance (i.e. concrete dataset) to be evaluated.\r\n",
    "We can furthermore use the included `ConfigSpace` in order to sample a concrete configuration and evaluate it: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Set an instance\n",
    "bench.set_instance(\"3945\")\n",
    "# Sample a point from the configspace (containing parameters for the instance and budget)\n",
    "value = bench.config_space.sample_configuration(1).get_dictionary()\n",
    "# Evaluate\n",
    "print(bench.objective_function(value))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'time': 1.017689, 'val_accuracy': 95.50793, 'val_cross_entropy': 0.43462884, 'val_balanced_accuracy': 0.50362957, 'test_cross_entropy': 0.5234015, 'test_balanced_accuracy': 0.48451677}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "value"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'OpenML_task_id': '3945',\n",
       " 'batch_size': 18,\n",
       " 'epoch': 24,\n",
       " 'learning_rate': 0.04011181906516829,\n",
       " 'max_dropout': 0.06693093775605241,\n",
       " 'max_units': 186.50635166676946,\n",
       " 'momentum': 0.34280065060609743,\n",
       " 'num_layers': 4,\n",
       " 'weight_decay': 0.07159902325199882}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# And the corresponding space we optimize over.\n",
    "bench.get_opt_space(\"3945\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    OpenML_task_id, Type: Constant, Value: 3945\n",
       "    batch_size, Type: UniformInteger, Range: [16, 512], Default: 91, on log-scale\n",
       "    learning_rate, Type: UniformFloat, Range: [0.00010000000000000009, 0.10000000000000002], Default: 0.0031622777, on log-scale\n",
       "    max_dropout, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.5\n",
       "    max_units, Type: UniformFloat, Range: [63.99999999999998, 1024.0], Default: 256.0, on log-scale\n",
       "    momentum, Type: UniformFloat, Range: [0.1, 0.99], Default: 0.545\n",
       "    num_layers, Type: UniformInteger, Range: [1, 5], Default: 3\n",
       "    weight_decay, Type: UniformFloat, Range: [1e-05, 0.1], Default: 0.050005"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A working example\r\n",
    "\r\n",
    "In order to demonstrate using YAHPO Gym more in-depth we provide a full example benchmarking `HPBandSter` on an `lcbench` task.\r\n",
    "We again start by importing the relevant modules:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from yahpo_gym import benchmark_set\n",
    "import yahpo_gym.benchmarks.lcbench\n",
    "import time\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can define a worker class as required by `HPBandSter` that internally calls our `objective_function`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from hpbandster.core.worker import Worker\n",
    "import hpbandster.core.nameserver as hpns\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "\n",
    "class lcbench(Worker):\n",
    "\n",
    "    def __init__(self, *args, sleep_interval=0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.bench = bench\n",
    "        self.sleep_interval = sleep_interval\n",
    "\n",
    "    def compute(self, config, budget, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            config: dictionary containing the sampled configurations by the optimizer\n",
    "            budget: (float) amount of epochs the model can use to train\n",
    "\n",
    "        Returns:\n",
    "            dictionary with mandatory fields:\n",
    "                \"loss\" (scalar)\n",
    "                \"info\" (dict)\n",
    "        \"\"\"\n",
    "\n",
    "        config.update({\"epoch\": int(np.round(budget))})  # update epoch\n",
    "        result = bench.objective_function(config)  # evaluate\n",
    "\n",
    "        time.sleep(self.sleep_interval)\n",
    "\n",
    "        return({\n",
    "                    \"loss\": - result.get(\"val_accuracy\"),  # we want to maximize validation accuracy\n",
    "                    \"info\": \"empty\"\n",
    "                })\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "        # sets OpenML_task_id constant to \"3945\" and removes the epoch fidelity parameter\n",
    "        cs = bench.get_opt_space(instance = \"3945\", drop_fidelity_params = True)\n",
    "        return(cs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using this worker class, we can now run the full benchmark:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Initialize the set providing a scenario\n",
    "bench = benchmark_set.BenchmarkSet(\"lcbench\")\n",
    "# Choose an instance\n",
    "bench.set_instance(\"3945\")\n",
    "\n",
    "# Start up the nameserver\n",
    "NS = hpns.NameServer(run_id=\"lcbench\", host=\"127.0.0.1\", port=None)\n",
    "NS.start()\n",
    "\n",
    "# Run BOHB\n",
    "w = lcbench(sleep_interval=0, nameserver=\"127.0.0.1\", run_id =\"lcbench\")\n",
    "w.run(background=True)\n",
    "\n",
    "bohb = BOHB(configspace=w.get_configspace(),\n",
    "            run_id=\"lcbench\", nameserver=\"127.0.0.1\",\n",
    "            min_budget=1, max_budget=52)\n",
    "\n",
    "res = bohb.run(n_iterations=1)\n",
    "\n",
    "bohb.shutdown(shutdown_workers=True)\n",
    "NS.shutdown()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "17:43:14 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7fc7bf1230d0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "17:43:14 DISPATCHER: started the 'discover_worker' thread\n",
      "17:43:14 wait_for_workers trying to get the condition\n",
      "17:43:14 DISPATCHER: started the 'job_runner' thread\n",
      "17:43:14 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "17:43:14 WORKER: start listening for jobs\n",
      "17:43:14 DISPATCHER: Pyro daemon running on localhost:33199\n",
      "17:43:14 DISPATCHER: Starting worker discovery\n",
      "17:43:14 DISPATCHER: Found 1 potential workers, 0 currently in the pool.\n",
      "17:43:14 DISPATCHER: discovered new worker, hpbandster.run_lcbench.worker.flo-x380.979188140498118664576\n",
      "17:43:14 HBMASTER: number of workers changed to 1\n",
      "17:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "17:43:14 Enough workers to start this run!\n",
      "17:43:14 adjust_queue_size: lock accquired\n",
      "17:43:14 HBMASTER: starting run at 1632930194.9800372\n",
      "17:43:14 HBMASTER: adjusted queue size to (0, 1)\n",
      "17:43:14 DISPATCHER: Finished worker discovery\n",
      "17:43:14 start sampling a new configuration.\n",
      "17:43:14 DISPATCHER: Trying to submit another job.\n",
      "17:43:14 done sampling a new configuration.\n",
      "17:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "17:43:14 HBMASTER: schedule new run for iteration 0\n",
      "17:43:14 HBMASTER: trying submitting job (0, 0, 0) to dispatcher\n",
      "17:43:14 HBMASTER: submitting job (0, 0, 0) to dispatcher\n",
      "17:43:14 DISPATCHER: trying to submit job (0, 0, 0)\n",
      "17:43:14 DISPATCHER: trying to notify the job_runner thread.\n",
      "17:43:14 HBMASTER: job (0, 0, 0) submitted to dispatcher\n",
      "17:43:14 DISPATCHER: Trying to submit another job.\n",
      "17:43:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "17:43:14 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_lcbench.worker.flo-x380.979188140498118664576\n",
      "17:43:14 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_lcbench.worker.flo-x380.979188140498118664576\n",
      "17:43:14 WORKER: start processing job (0, 0, 0)\n",
      "17:43:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "17:43:14 WORKER: args: ()\n",
      "17:43:14 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 20, 'learning_rate': 0.0006136152871575448, 'max_dropout': 0.09949400059982938, 'max_units': 461.45750653807886, 'momentum': 0.8743691420109518, 'num_layers': 3, 'weight_decay': 0.04682715559002122}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "17:43:15 WORKER: done with job (0, 0, 0), trying to register it.\n",
      "Exception in thread oneway-call:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 495, in ser_default_class\n",
      "    value = obj.__getstate__()\n",
      "AttributeError: 'numpy.float32' object has no attribute '__getstate__'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 507, in ser_default_class\n",
      "    value = dict(vars(obj))  # make sure we can serialize anything that resembles a dict\n",
      "TypeError: vars() argument must have __dict__ attribute\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/threading.py\", line 954, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/Pyro4/core.py\", line 1893, in run\n",
      "    super(_OnewayCallThread, self).run()\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/threading.py\", line 892, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/hpbandster/core/worker.py\", line 215, in start_computation\n",
      "    callback.register_result(id, result)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/Pyro4/core.py\", line 185, in __call__\n",
      "    return self.__send(self.__name, args, kwargs)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/Pyro4/core.py\", line 437, in _pyroInvoke\n",
      "    data, compressed = serializer.serializeCall(objectId, methodname, vargs, kwargs, compress=config.COMPRESSION)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/Pyro4/util.py\", line 176, in serializeCall\n",
      "    data = self.dumpsCall(obj, method, vargs, kwargs)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/Pyro4/util.py\", line 602, in dumpsCall\n",
      "    return serpent.dumps((obj, method, vargs, kwargs), module_in_classname=True)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 69, in dumps\n",
      "    return Serializer(indent, module_in_classname, bytes_repr).serialize(obj)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 229, in serialize\n",
      "    self._serialize(obj, out, 0)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 255, in _serialize\n",
      "    return self.dispatch[t](self, obj, out, level)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 319, in ser_builtins_tuple\n",
      "    serialize(elt, out, level + 1)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 255, in _serialize\n",
      "    return self.dispatch[t](self, obj, out, level)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 319, in ser_builtins_tuple\n",
      "    serialize(elt, out, level + 1)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 255, in _serialize\n",
      "    return self.dispatch[t](self, obj, out, level)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 392, in ser_builtins_dict\n",
      "    serialize(value, out, level + 1)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 255, in _serialize\n",
      "    return self.dispatch[t](self, obj, out, level)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 392, in ser_builtins_dict\n",
      "    serialize(value, out, level + 1)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 274, in _serialize\n",
      "    func(self, obj, out, level)\n",
      "  File \"/home/flo/miniconda3/envs/yahpo/lib/python3.9/site-packages/serpent.py\", line 517, in ser_default_class\n",
      "    raise TypeError(\"don't know how to serialize class \" +\n",
      "TypeError: don't know how to serialize class <class 'numpy.float32'>. Give it vars() or an appropriate __getstate__\n",
      "17:44:14 DISPATCHER: Starting worker discovery\n",
      "17:44:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "17:44:14 DISPATCHER: Finished worker discovery\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "and print the results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "id2config = res.get_id2config_mapping()\n",
    "id2config"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "incumbent = res.get_incumbent_id()\n",
    "incumbent"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "print(\"Best found configuration:\", id2config[incumbent][\"config\"])\n",
    "print(\"A total of %i unique configurations where sampled.\" % len(id2config.keys()))\n",
    "print(\"A total of %i runs where executed.\" % len(res.get_all_runs()))\n",
    "print(\"Total budget corresponds to %.1f full function evaluations.\"%(sum([r.budget for r in res.get_all_runs()])/1))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('yahpo': conda)"
  },
  "interpreter": {
   "hash": "9506a27cd19bab90231c653dbdb6173feaea5008b53f9c3a9ea539bcb65e37c0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}