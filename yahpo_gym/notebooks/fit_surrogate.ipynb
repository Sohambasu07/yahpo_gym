{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "%load_ext autoreload\r\n",
                "%autoreload 2\r\n",
                "from yahpo_train.cont_normalization import ContNormalization\r\n",
                "from yahpo_train.model  import *\r\n",
                "from yahpo_train.metrics import *\r\n",
                "from yahpo_gym.benchmarks import lcbench, rbv2\r\n",
                "from yahpo_gym.configuration import cfg"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "cc = cfg('rbv2_glmnet')\r\n",
                "dls = dl_from_config(cc, bs=2048)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "f = FFSurrogateModel(dls, layers=[512,512])\r\n",
                "l = SurrogateTabularLearner(dls, f, loss_func=nn.MSELoss(reduction='mean'), metrics=nn.MSELoss)\r\n",
                "l.metrics = [AvgTfedMetric(mae),  AvgTfedMetric(r2), AvgTfedMetric(spearman)]\r\n",
                "l.add_cb(MixHandler)\r\n",
                "l.add_cb(EarlyStoppingCallback(patience=3))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "NLL YJ: -2882590.9946846357\n",
                        "NLL Scaler: -3832622.3806794905\n",
                        "NLL Scaler: nan\n",
                        "NLL Scaler: nan\n",
                        "NLL Scaler: -4061630.370804108\n",
                        "NLL YJ: 6169796.717844549\n",
                        "NLL Scaler: 2499197.895726821\n",
                        "NLL Scaler: 1793369.409136417\n",
                        "NLL Scaler: 4898619.587748892\n",
                        "NLL Scaler: -2082691.5082045258\n",
                        "NLL YJ: -2888510.3327216604\n",
                        "NLL Scaler: -3836567.0950524095\n",
                        "NLL Scaler: -2543764.725332674\n",
                        "NLL Scaler: 561485.2380746134\n",
                        "NLL Scaler: -4136480.030878919\n",
                        "NLL YJ: 7373113.906852744\n",
                        "NLL Scaler: 465265.1473603297\n",
                        "NLL Scaler: -1396655.7581372545\n",
                        "NLL Scaler: 1708594.5248908843\n",
                        "NLL Scaler: -6253908.921465752\n",
                        "NLL YJ: -3886496.2129677013\n",
                        "NLL Scaler: -4435837.95078848\n",
                        "NLL Scaler: nan\n",
                        "NLL Scaler: nan\n",
                        "NLL Scaler: -4602672.549334051\n",
                        "NLL YJ: -2169029.680202037\n",
                        "NLL Scaler: -3031860.049233366\n",
                        "NLL Scaler: nan\n",
                        "NLL Scaler: nan\n",
                        "NLL Scaler: -3231503.4697811585\n",
                        "NLL YJ: -5434002.887308268\n",
                        "NLL Scaler: -5847599.219139412\n",
                        "NLL Scaler: -5664787.009221261\n",
                        "NLL Scaler: -2559537.2431321847\n",
                        "NLL Scaler: -6293085.394365977\n",
                        "NLL YJ: -1914924.2507311567\n",
                        "NLL Scaler: -3046667.2297461885\n",
                        "NLL Scaler: -2145931.6668481627\n",
                        "NLL Scaler: 959318.515602118\n",
                        "NLL Scaler: -3751126.0417859904\n",
                        "NLL YJ: 2311318.5934511437\n",
                        "NLL Scaler: 188732.3608389266\n",
                        "NLL Scaler: -844136.7765331384\n",
                        "NLL Scaler: 2261113.432773\n",
                        "NLL Scaler: -2830142.339348078\n",
                        "NLL YJ: -6340287.675878146\n",
                        "NLL Scaler: -3893331.5043015764\n",
                        "NLL Scaler: -2336506.2669158746\n",
                        "NLL Scaler: 768743.8693331243\n",
                        "NLL Scaler: -4559613.010865976\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<yahpo_train.model.SurrogateTabularLearner at 0x2080032e700>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 10
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "[x.scaler for x in l.embds_dbl] + [x.scaler for x in l.embds_tgt]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[<yahpo_train.cont_normalization.Scaler at 0x20800090eb0>,\n",
                            " <yahpo_train.cont_normalization.Scaler at 0x20800090100>,\n",
                            " <yahpo_train.cont_normalization.Scaler at 0x208000a7e20>,\n",
                            " <yahpo_train.cont_normalization.Scaler at 0x208000a7100>,\n",
                            " <yahpo_train.cont_normalization.Scaler at 0x2080032ebb0>,\n",
                            " <yahpo_train.cont_normalization.Scaler at 0x2080032eb20>,\n",
                            " <yahpo_train.cont_normalization.Scaler at 0x2080032ee20>,\n",
                            " <yahpo_train.cont_normalization.Scaler at 0x2085fd15430>,\n",
                            " <yahpo_train.cont_normalization.Scaler at 0x20800090df0>,\n",
                            " None]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 13
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "l.fit_flat_cos(5, 1e-3)\r\n",
                "for p in l.model.wide.parameters():\r\n",
                "    p.requires_grad = False\r\n",
                "l.fit_flat_cos(5, 1e-4)"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ],
                        "text/html": [
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: left;\">\n",
                            "      <th>epoch</th>\n",
                            "      <th>train_loss</th>\n",
                            "      <th>valid_loss</th>\n",
                            "      <th>mae</th>\n",
                            "      <th>r2</th>\n",
                            "      <th>spearman</th>\n",
                            "      <th>time</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>0</td>\n",
                            "      <td>0.005727</td>\n",
                            "      <td>0.004985</td>\n",
                            "      <td>[0.03071178 0.03134002 0.22002012 0.0893494  5.2209722  0.08186299]</td>\n",
                            "      <td>[ 0.91939017  0.96216957 -0.02699783  0.84406365  0.02074665  0.59069368]</td>\n",
                            "      <td>[0.92895188 0.89435466 0.70853261 0.91897454 0.71040431 0.90916701]</td>\n",
                            "      <td>03:50</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>0.004924</td>\n",
                            "      <td>0.004805</td>\n",
                            "      <td>[0.02959018 0.03119148 0.21869054 0.09277981 5.211237   0.07693558]</td>\n",
                            "      <td>[ 0.91571131  0.96586696 -0.05582809  0.80882739  0.01837675  0.62739999]</td>\n",
                            "      <td>[0.93200834 0.89901171 0.485341   0.90717091 0.68058017 0.90884171]</td>\n",
                            "      <td>03:51</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>0.004607</td>\n",
                            "      <td>0.004586</td>\n",
                            "      <td>[0.02676723 0.02445112 0.21325743 0.08717156 5.22018653 0.0751325 ]</td>\n",
                            "      <td>[ 0.9180749   0.97025915 -0.01602825  0.80046624  0.02038021  0.63474804]</td>\n",
                            "      <td>[0.93628577 0.90634329 0.60087258 0.90953818 0.66442099 0.90373651]</td>\n",
                            "      <td>03:51</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>0.004433</td>\n",
                            "      <td>0.004878</td>\n",
                            "      <td>[0.02837784 0.02633818 0.21872403 0.09404772 5.19595637 0.07525598]</td>\n",
                            "      <td>[ 0.92199831  0.96338459 -0.06185373  0.78239802  0.02522013  0.62443524]</td>\n",
                            "      <td>[0.9357698  0.90369516 0.40442538 0.89982081 0.67237838 0.89769475]</td>\n",
                            "      <td>03:52</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4</td>\n",
                            "      <td>0.004222</td>\n",
                            "      <td>0.004666</td>\n",
                            "      <td>[0.0251466  0.02458286 0.2133736  0.08416838 5.2053894  0.0749461 ]</td>\n",
                            "      <td>[ 0.92358888  0.96644786 -0.03229268  0.78446398  0.02389078  0.62361928]</td>\n",
                            "      <td>[0.93503215 0.9047265  0.5045005  0.8977712  0.6712361  0.89269219]</td>\n",
                            "      <td>03:52</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>"
                        ]
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ],
                        "text/html": [
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: left;\">\n",
                            "      <th>epoch</th>\n",
                            "      <th>train_loss</th>\n",
                            "      <th>valid_loss</th>\n",
                            "      <th>mae</th>\n",
                            "      <th>r2</th>\n",
                            "      <th>spearman</th>\n",
                            "      <th>time</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>0</td>\n",
                            "      <td>0.004216</td>\n",
                            "      <td>0.004673</td>\n",
                            "      <td>[0.02524103 0.0245316  0.21280765 0.08484684 5.21068137 0.07540551]</td>\n",
                            "      <td>[ 0.92661092  0.96637061 -0.02811578  0.78393324  0.02250905  0.61715866]</td>\n",
                            "      <td>[0.93458675 0.90504417 0.52882816 0.89878155 0.67181911 0.88967823]</td>\n",
                            "      <td>03:51</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>0.004159</td>\n",
                            "      <td>0.004769</td>\n",
                            "      <td>[0.02574775 0.02426513 0.21297741 0.08609769 5.20385468 0.07493126]</td>\n",
                            "      <td>[ 0.92098981  0.96533756 -0.02518601  0.77481419  0.02321787  0.61824871]</td>\n",
                            "      <td>[0.9340293  0.90441931 0.48954833 0.89393443 0.67454495 0.88872414]</td>\n",
                            "      <td>03:51</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>0.004176</td>\n",
                            "      <td>0.004732</td>\n",
                            "      <td>[0.02525586 0.02410149 0.21396262 0.08792935 5.19457071 0.07562068]</td>\n",
                            "      <td>[ 0.92380711  0.96659612 -0.03715277  0.7663898   0.02456437  0.61749188]</td>\n",
                            "      <td>[0.93574685 0.9049795  0.45129179 0.89307266 0.69069685 0.88344027]</td>\n",
                            "      <td>03:46</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>0.004184</td>\n",
                            "      <td>0.004750</td>\n",
                            "      <td>[0.02544605 0.02528027 0.21303462 0.08676766 5.18418809 0.07531716]</td>\n",
                            "      <td>[ 0.92253676  0.96622385 -0.03302443  0.76761085  0.02903252  0.61915603]</td>\n",
                            "      <td>[0.93463414 0.90369132 0.487074   0.8928585  0.68202158 0.88543753]</td>\n",
                            "      <td>03:45</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>"
                        ]
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "No improvement since epoch 0: early stopping\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "l.export_onnx(cfg)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "c:\\Users\\flo\\Documents\\yahpo_gym\\yahpo_train\\yahpo_train\\cont_normalization.py:50: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if torch.abs(lmbda) < self.eps:\n",
                        "c:\\Users\\flo\\Documents\\yahpo_gym\\yahpo_train\\yahpo_train\\cont_normalization.py:56: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if torch.abs(lmbda - 2.) <= self.eps:\n",
                        "c:\\Users\\flo\\Documents\\yahpo_gym\\yahpo_train\\yahpo_train\\model.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  ys = [e(ys[:,i]).unsqueeze(1) for i,e in enumerate(self.embds_tgt)]\n",
                        "c:\\Users\\flo\\Documents\\yahpo_gym\\yahpo_train\\yahpo_train\\cont_normalization.py:84: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  return x\n",
                        "c:\\Users\\flo\\Documents\\yahpo_gym\\yahpo_train\\yahpo_train\\cont_normalization.py:91: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  return x\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "source": [
                " class Scaler():\r\n",
                "    def  __init__(self, forward, invert):\r\n",
                "        self.fwd = forward\r\n",
                "        self.inv = invert\r\n",
                "\r\n",
                "    def forward(self, x):\r\n",
                "            return self.fwd(x)\r\n",
                "\r\n",
                "    def invert(self,x):\r\n",
                "        return self.inv(x)\r\n",
                "\r\n",
                " scs = [Scaler(torch.log1p, torch.expm1), Scaler(torch.log10, lambda x: torch.pow(10., x)),Scaler(torch.log2, torch.exp2), Scaler(lambda x: torch.exp(-x), lambda x: - torch.log(x))]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "source": [
                "x= torch.rand(100)\r\n",
                "for sc in scs:\r\n",
                "    fwd = sc.forward(x)\r\n",
                "    print(torch.mean(sc.invert(fwd) - x))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor(-4.3213e-09)\n",
                        "tensor(-7.3342e-10)\n",
                        "tensor(-1.9278e-09)\n",
                        "tensor(-3.3295e-10)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor([ 0.0000e+00,  0.0000e+00,  5.9605e-08,  0.0000e+00,  0.0000e+00,\n",
                            "        -5.9605e-08,  0.0000e+00,  0.0000e+00, -5.9605e-08,  0.0000e+00,\n",
                            "         0.0000e+00,  0.0000e+00,  5.9605e-08, -5.9605e-08,  0.0000e+00,\n",
                            "        -5.9605e-08,  0.0000e+00,  5.9605e-08,  5.9605e-08,  5.9605e-08,\n",
                            "         5.9605e-08,  0.0000e+00,  5.9605e-08, -5.9605e-08,  5.9605e-08,\n",
                            "        -5.9605e-08,  0.0000e+00,  5.9605e-08,  5.9605e-08, -5.9605e-08,\n",
                            "         0.0000e+00,  5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
                            "         0.0000e+00,  5.9605e-08,  0.0000e+00,  5.9605e-08,  5.9605e-08,\n",
                            "         5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
                            "         5.9605e-08,  0.0000e+00, -5.9605e-08, -5.9605e-08,  0.0000e+00,\n",
                            "        -5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
                            "         0.0000e+00, -5.9605e-08,  0.0000e+00, -5.9605e-08, -5.9605e-08,\n",
                            "         0.0000e+00,  0.0000e+00, -5.9605e-08,  0.0000e+00,  5.9605e-08,\n",
                            "         0.0000e+00,  0.0000e+00,  5.9605e-08, -5.9605e-08,  5.9605e-08,\n",
                            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9605e-08,\n",
                            "         0.0000e+00, -5.9605e-08,  0.0000e+00,  0.0000e+00, -5.9605e-08,\n",
                            "        -5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
                            "         5.9605e-08,  0.0000e+00,  5.9605e-08,  0.0000e+00, -5.9605e-08,\n",
                            "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.9605e-08,\n",
                            "         5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.9605e-08])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 45
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit (conda)"
        },
        "interpreter": {
            "hash": "935079f3ab4b06ec76910fd5af9cfadee87e8a756fe17d7789065f69c1782d29"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}